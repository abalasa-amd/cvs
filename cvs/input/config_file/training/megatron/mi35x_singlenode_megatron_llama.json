{

    "config":
    {
        "container_image": "rocm/megatron-lm:v25.9_gfx950",
        "container_name": "megatron_llama3.1_310",
        "_example_nnodes": "4",
        "nnodes": "<changeme>-no of nodes to run singlenode training",
        "master_address": "localhost",
        "_example_training_iterations": "30",
        "training_iterations": "<changeme>",
        "hf_token_file": "/home/{user-id}/.hf_token",
        "shm_size": "128G",
        "_comments_data_cache_dir": "This path should be accessible from all nodes like a common FS like NFS for distributed training",
        "data_cache_dir": "/home/{user-id}/cache",
        "mock_data": "True",
        "log_dir": "/home/{user-id}/LOG_DIR",
        "dataset_source": 
        {
        },
        "container_config":
        {
            "device_list": [ "/dev/dri", "/dev/kfd" ],
            "volume_dict":
            {
            "/home/{user-id}": "/home/{user-id}"
            }
        }
    },
    "model_params":
    {
        "single_node":
        {
             "llama3_1_8b":
             {
                 "mi350":
                 {
                     "tokenizer_model": "NousResearch/Meta-Llama-3-8B",
                     "model_size": "8",
                     "batch_size": "128",
                     "micro_batch_size": "4",
                     "precision": "TE_FP8",
                     "sequence_length": "8192",
		     "fsdp": "0",
                     "tensor_parallelism": "1",
                     "pipeline_parallelism": "1",
                     "recompute": "0",
                     "result_dict":
                     {
                         "tokens_per_gpu": "18000.0"
                     }
                 },
                 "mi355":
                 {
                     "tokenizer_model": "NousResearch/Meta-Llama-3-8B",
                     "model_size": "8",
                     "batch_size": "128",
                     "micro_batch_size": "4",
                     "precision": "TE_FP8",
                     "sequence_length": "8192",
		     "fsdp": "1",
                     "tensor_parallelism": "1",
                     "pipeline_parallelism": "1",
                     "recompute": "1",
                     "result_dict":
                     {
                         "tokens_per_gpu": "20000.0"
                     }
                 }
             },
             "llama3_1_70b":
             {
                 "mi350":
                 {
                     "tokenizer_model": "NousResearch/Meta-Llama-3-70B",
                     "model_size": "70",
                     "batch_size": "24",
                     "micro_batch_size": "3",
                     "precision": "TE_FP16",
                     "sequence_length": "8192",
		     "fsdp": "1",
                     "tensor_parallelism": "1",
                     "pipeline_parallelism": "1",
                     "recompute": "1",
                     "result_dict":
                     {
                         "tokens_per_gpu": "2000.0"
                     }
                 },
                 "mi355":
                 {
                     "tokenizer_model": "NousResearch/Meta-Llama-3-70B",
                     "model_size": "70",
                     "batch_size": "24",
                     "micro_batch_size": "3",
                     "precision": "TE_FP16",
                     "sequence_length": "8192",
		     "fsdp": "1",
                     "tensor_parallelism": "1",
                     "pipeline_parallelism": "1",
                     "recompute": "1",
                     "result_dict":
                     {
                         "tokens_per_gpu": "2100.0"
                     }
                 }
             }
        }

    }

}
