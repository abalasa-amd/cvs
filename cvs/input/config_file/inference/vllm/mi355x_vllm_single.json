{
    "config": {
        "container_image": "rocm/7.0:rocm7.0_ubuntu_22.04_vllm_0.10.1_instinct_20250927_rc1",
        "container_name": "vllm_inference_rocm",
        "nnodes": "1",
        "benchmark_server_script_path": "/home/{user-id}/benchmark_server_scripts/",
        "benchmark_script_repo": "https://github.com/kimbochen/bench_serving.git",
        "hf_token_file": "/home/{user-id}/.hf_token",
        "shm_size": "16G",
        "log_dir": "/home/{user-id}/LOGS",
        "data_cache_dir": "/it-share/models/",
        "container_config": {
            "device_list": [
                "/dev/dri",
                "/dev/kfd",
                "/dev/mem"
            ],
            "volume_dict": {
                "/home/{user-id}": "/home/{user-id}",
                "/it-share/models/": "/models"
            },
            "env_dict": {
                "HF_HUB_CACHE": "/models/huggingface-cache"
            }
        }
    },
    "benchmark_params": {
        "gpt-oss-120b": {
            "container_image": "rocm/7.0:rocm7.0_ubuntu_22.04_vllm_0.10.1_instinct_20250927_rc1",
            "backend": "vllm",
            "base_url": "http://0.0.0.0",
            "port_no": "8888",
            "_example_dataset_name": "sharegpt|hf|random|sonnet|burstgpt",
            "dataset_name": "random",
            "concurrency_levels": [
                16,
                32,
                64
            ],
            "model": "openai/gpt-oss-120b",
            "num_prompts": "3200",
            "sequence_combinations": [
                {
                    "isl": "1024",
                    "osl": "1024",
                    "name": "balanced"
                },
                {
                    "isl": "1024",
                    "osl": "8192",
                    "name": "long_generation"
                },
                {
                    "isl": "8192",
                    "osl": "1024",
                    "name": "long_context"
                }
            ],
            "burstiness": "1.0",
            "seed": "0",
            "request_rate": "inf",
            "max_model_length": "9216",
            "random_range_ratio": "0.8",
            "random_prefix_len": "0",
            "tensor_parallelism": "1",
            "_example_tokenizer_mode": "auto|slow|mistral|custom",
            "tokenizer_mode": "auto",
            "percentile_metrics": "ttft,tpot,itl,e2el",
            "metric_percentiles": "99",
            "server_script": "gpt-oss-120b_fp4_mi355x_vllm_docker.sh",
            "bench_serv_script": "benchmark_serving.py",
            "result_dict": {
                "ISL=1024,OSL=1024,TP=1,CONC=16": {
                    "total_throughput_per_sec": "4651",
                    "mean_ttft_ms": "70",
                    "mean_tpot_ms": "8"
                },
                "ISL=1024,OSL=1024,TP=1,CONC=32": {
                    "total_throughput_per_sec": "7043",
                    "mean_ttft_ms": "180",
                    "mean_tpot_ms": "9"
                },
                "ISL=1024,OSL=1024,TP=1,CONC=64": {
                    "total_throughput_per_sec": "10677",
                    "mean_ttft_ms": "76",
                    "mean_tpot_ms": "13"
                },
                "ISL=1024,OSL=8192,TP=1,CONC=16": {
                    "total_throughput_per_sec": "2735",
                    "mean_ttft_ms": "57",
                    "mean_tpot_ms": "7"
                },
                "ISL=1024,OSL=8192,TP=1,CONC=32": {
                    "total_throughput_per_sec": "4038",
                    "mean_ttft_ms": "67",
                    "mean_tpot_ms": "10"
                },
                "ISL=1024,OSL=8192,TP=1,CONC=64": {
                    "total_throughput_per_sec": "6140",
                    "mean_ttft_ms": "93",
                    "mean_tpot_ms": "13"
                },
                "ISL=8192,OSL=1024,TP=1,CONC=16": {
                    "total_throughput_per_sec": "16509",
                    "mean_ttft_ms": "335",
                    "mean_tpot_ms": "24"
                },
                "ISL=8192,OSL=1024,TP=1,CONC=32": {
                    "total_throughput_per_sec": "22072",
                    "mean_ttft_ms": "320",
                    "mean_tpot_ms": "19"
                },
                "ISL=8192,OSL=1024,TP=1,CONC=64": {
                    "total_throughput_per_sec": "28863",
                    "mean_ttft_ms": "280",
                    "mean_tpot_ms": "22"
                }
            }
        },
        "qwen3-235b": {
            "container_image": "amdsiloai/vllm:2025111-0.11.1rc2-qwen3",
            "backend": "vllm",
            "base_url": "http://0.0.0.0",
            "port_no": "8888",
            "dataset_name": "random",
            "concurrency_levels": [
                16,
                32,
                64
            ],
            "model": "Qwen/Qwen3-235B-A22B-Instruct-2507",
            "num_prompts": "3200",
            "sequence_combinations": [
                {
                    "isl": "1024",
                    "osl": "1024",
                    "name": "balanced"
                },
                {
                    "isl": "1024",
                    "osl": "8192",
                    "name": "long_generation"
                },
                {
                    "isl": "8192",
                    "osl": "1024",
                    "name": "long_context"
                }
            ],
            "burstiness": "1.0",
            "seed": "0",
            "request_rate": "inf",
            "max_model_length": "9216",
            "random_range_ratio": "0.8",
            "random_prefix_len": "0",
            "tensor_parallelism": "8",
            "tokenizer_mode": "auto",
            "percentile_metrics": "ttft,tpot,itl,e2el",
            "metric_percentiles": "99",
            "server_script": "qwen3-235b-bf16_mi355x_vllm_docker.sh",
            "bench_serv_script": "benchmark_serving.py",
            "result_dict": {
                "ISL=1024,OSL=1024,TP=8,CONC=16": {
                    "total_throughput_per_sec": "2000",
                    "mean_ttft_ms": "850",
                    "mean_tpot_ms": "18"
                },
                "ISL=1024,OSL=1024,TP=8,CONC=32": {
                    "total_throughput_per_sec": "3435",
                    "mean_ttft_ms": "80",
                    "mean_tpot_ms": "10"
                },
                "ISL=1024,OSL=1024,TP=8,CONC=64": {
                    "total_throughput_per_sec": "5840",
                    "mean_ttft_ms": "260",
                    "mean_tpot_ms": "10"
                },
                "ISL=1024,OSL=8192,TP=8,CONC=16": {
                    "total_throughput_per_sec": "1119",
                    "mean_ttft_ms": "415",
                    "mean_tpot_ms": "25"
                },
                "ISL=1024,OSL=8192,TP=8,CONC=32": {
                    "total_throughput_per_sec": "1876",
                    "mean_ttft_ms": "70",
                    "mean_tpot_ms": "10"
                },
                "ISL=1024,OSL=8192,TP=8,CONC=64": {
                    "total_throughput_per_sec": "3139",
                    "mean_ttft_ms": "310",
                    "mean_tpot_ms": "14"
                },
                "ISL=8192,OSL=1024,TP=8,CONC=16": {
                    "total_throughput_per_sec": "7476",
                    "mean_ttft_ms": "300",
                    "mean_tpot_ms": "21"
                },
                "ISL=8192,OSL=1024,TP=8,CONC=32": {
                    "total_throughput_per_sec": "11312",
                    "mean_ttft_ms": "355",
                    "mean_tpot_ms": "27"
                },
                "ISL=8192,OSL=1024,TP=8,CONC=64": {
                    "total_throughput_per_sec": "16082",
                    "mean_ttft_ms": "450",
                    "mean_tpot_ms": "39"
                }
            }
        },
        "qwen3-80b": {
            "container_image": "rocm/vllm-dev:nightly",
            "backend": "vllm",
            "base_url": "http://0.0.0.0",
            "port_no": "8888",
            "dataset_name": "random",
            "concurrency_levels": [
                16,
                32,
                64
            ],
            "model": "Qwen/Qwen3-Next-80B-A3B-Instruct",
            "num_prompts": "3200",
            "sequence_combinations": [
                {
                    "isl": "1024",
                    "osl": "1024",
                    "name": "balanced"
                },
                {
                    "isl": "1024",
                    "osl": "8192",
                    "name": "long_generation"
                },
                {
                    "isl": "8192",
                    "osl": "1024",
                    "name": "long_context"
                }
            ],
            "burstiness": "1.0",
            "seed": "0",
            "request_rate": "inf",
            "max_model_length": "9216",
            "random_range_ratio": "0.8",
            "random_prefix_len": "0",
            "tensor_parallelism": "1",
            "tokenizer_mode": "auto",
            "percentile_metrics": "ttft,tpot,itl,e2el",
            "metric_percentiles": "99",
            "server_script": "qwen3-80b-bf16_mi355x_vllm_docker.sh",
            "bench_serv_script": "benchmark_serving.py",
            "result_dict": {
                "ISL=1024,OSL=1024,TP=1,CONC=16": {
                    "total_throughput_per_sec": "2003",
                    "mean_ttft_ms": "69",
                    "mean_tpot_ms": "9"
                },
                "ISL=1024,OSL=1024,TP=1,CONC=32": {
                    "total_throughput_per_sec": "3155",
                    "mean_ttft_ms": "69",
                    "mean_tpot_ms": "12"
                },
                "ISL=1024,OSL=1024,TP=1,CONC=64": {
                    "total_throughput_per_sec": "4570",
                    "mean_ttft_ms": "375",
                    "mean_tpot_ms": "23"
                },
                "ISL=1024,OSL=8192,TP=1,CONC=16": {
                    "total_throughput_per_sec": "1200",
                    "mean_ttft_ms": "84",
                    "mean_tpot_ms": "12"
                },
                "ISL=1024,OSL=8192,TP=1,CONC=32": {
                    "total_throughput_per_sec": "1800",
                    "mean_ttft_ms": "200",
                    "mean_tpot_ms": "12"
                },
                "ISL=1024,OSL=8192,TP=1,CONC=64": {
                    "total_throughput_per_sec": "2600",
                    "mean_ttft_ms": "768",
                    "mean_tpot_ms": "21"
                },
                "ISL=8192,OSL=1024,TP=1,CONC=16": {
                    "total_throughput_per_sec": "7500",
                    "mean_ttft_ms": "495",
                    "mean_tpot_ms": "16"
                },
                "ISL=8192,OSL=1024,TP=1,CONC=32": {
                    "total_throughput_per_sec": "11300",
                    "mean_ttft_ms": "280",
                    "mean_tpot_ms": "17"
                },
                "ISL=8192,OSL=1024,TP=1,CONC=64": {
                    "total_throughput_per_sec": "16000",
                    "mean_ttft_ms": "91",
                    "mean_tpot_ms": "18"
                }
            }
        },
        "deepseek-v31": {
            "container_image": "rocm/7.x-preview:rocm7.2_preview_ubuntu_22.04_vlm_0.10.1_instinct_20251029",
            "backend": "vllm",
            "base_url": "http://0.0.0.0",
            "port_no": "8888",
            "dataset_name": "random",
            "concurrency_levels": [
                16,
                32,
                64
            ],
            "model": "deepseek-ai/DeepSeek-V3.1",
            "num_prompts": "3200",
            "sequence_combinations": [
                {
                    "isl": "1024",
                    "osl": "1024",
                    "name": "balanced"
                },
                {
                    "isl": "1024",
                    "osl": "8192",
                    "name": "long_generation"
                }
            ],
            "burstiness": "1.0",
            "seed": "0",
            "request_rate": "inf",
            "max_model_length": "9216",
            "random_range_ratio": "0.8",
            "random_prefix_len": "0",
            "tensor_parallelism": "8",
            "tokenizer_mode": "auto",
            "percentile_metrics": "ttft,tpot,itl,e2el",
            "metric_percentiles": "99",
            "server_script": "dsr1_fp8_mi355x_vllm_docker.sh",
            "bench_serv_script": "benchmark_serving.py",
            "result_dict": {
                "ISL=1024,OSL=1024,TP=8,CONC=16": {
                    "total_throughput_per_sec": "1944",
                    "mean_ttft_ms": "84",
                    "mean_tpot_ms": "12"
                },
                "ISL=1024,OSL=1024,TP=8,CONC=32": {
                    "total_throughput_per_sec": "2939",
                    "mean_ttft_ms": "302",
                    "mean_tpot_ms": "21"
                },
                "ISL=1024,OSL=1024,TP=8,CONC=64": {
                    "total_throughput_per_sec": "4834",
                    "mean_ttft_ms": "250",
                    "mean_tpot_ms": "11"
                },
                "ISL=1024,OSL=8192,TP=8,CONC=16": {
                    "total_throughput_per_sec": "1109",
                    "mean_ttft_ms": "253",
                    "mean_tpot_ms": "19"
                },
                "ISL=1024,OSL=8192,TP=8,CONC=32": {
                    "total_throughput_per_sec": "1676",
                    "mean_ttft_ms": "305",
                    "mean_tpot_ms": "21"
                },
                "ISL=1024,OSL=8192,TP=8,CONC=64": {
                    "total_throughput_per_sec": "2716",
                    "mean_ttft_ms": "280",
                    "mean_tpot_ms": "13"
                }
            }
        }
    }
}
