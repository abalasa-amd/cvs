{

    "config":
    {
	"_comments__": "Config file created for 4 nodes, change expected results based on number of nodes",
        "container_image": "rocm/megatron-lm:v25.5_py310",
        "container_name": "megatron_llama3.1_310",
        "distributed_training": "True",
        "_example_nnodes": "4",
        "nnodes": "<changeme>",
        "_example_master_address": "X.X.X.X",
        "master_address": "<changeme>",
        "_example_training_iterations": "30",
        "training_iterations": "<changeme>",
        "_example_nic_type": "ainic|thor2|cx7",
        "nic_type": "<changeme>",
        "_example_nccl_ib_hca_list": "bnxt_re0,bnxt_re1,bnxt_re2,bnxt_re3,bnxt_re4,bnxt_re5,bnxt_re6,bnxt_re7",
        "nccl_ib_hca_list": "<changeme>",
        "_example_nccl_socket_ifname": "ens51f1np1",
        "nccl_socket_ifname": "<changeme>",
        "_example_gloo_socket_ifname": "ens51f1np1",
        "gloo_socket_ifname": "<changeme>",
        "_example_nccl_ib_gid_index": "3",
        "nccl_ib_gid_index": "<changeme>",
        "nccl_debug": "ERROR",
        "hf_token_file": "/home/{user-id}/.hf_token",
        "shm_size": "128G",
        "_comments_data_cache_dir": "This path should be accessible from all nodes like a common FS like NFS for distributed training",
        "data_cache_dir": "/home/{user-id}/cache",
        "mock_data": "True",
        "log_dir": "/home/{user-id}/LOG_DIR",
        "dataset_source": 
        {
        },
        "container_config":
        {
            "device_list": [ "/dev/dri", "/dev/kfd", "/dev/infiniband/rdma_cm" ],
            "volume_dict":
            {
            "/home/<changeme>": "/home/{user-id}",
            "/dev/infiniband": "/dev/infiniband",
            "/usr/local/lib/libbnxt_re-rdmav34.so": "/usr/lib/x86_64-linux-gnu/libibverbs/libbnxt_re-rdmav34.so.host",
            "/lib/libibverbs.d": "/lib/libibverbs.d",
            "/tmp/TRAINING_LOGS": "/workspace/Megatron-LM/output"
            }
        }
    },
    "model_params":
    {
        "multi_node":
        {
             "llama3_1_8b":
             {
                 "mi300x":
                 {
                     "tokenizer_model": "NousResearch/Meta-Llama-3-8B",
                     "model_size": "8",
                     "batch_size": "128",
                     "micro_batch_size": "2",
                     "precision": "TE_FP8",
                     "sequence_length": "8192",
                     "tensor_parallelism": "1",
                     "pipeline_parallelism": "1",
                     "recompute": "0",
                     "fsdp": "0",
                     "result_dict":
                     {
                         "_example_throughput_per_gpu": "610.0",
                         "_example_tokens_per_gpu": "12000.0",
                         "throughput_per_gpu": "<changeme>",
                         "tokens_per_gpu": "<changeme>"
                     }
                 },
                 "mi325":
                 {
                     "tokenizer_model": "NousResearch/Meta-Llama-3-8B",
                     "model_size": "8",
                     "batch_size": "128",
                     "micro_batch_size": "2",
                     "precision": "TE_FP8",
                     "sequence_length": "8192",
                     "tensor_parallelism": "1",
                     "pipeline_parallelism": "1",
                     "recompute": "0",
                     "fsdp": "0",
                     "result_dict":
                     {
                         "_example_throughput_per_gpu": "620.0",
                         "_example_tokens_per_gpu": "14000.0",
                         "throughput_per_gpu": "<changeme>",
                         "tokens_per_gpu": "<changeme>"
                     }
                 }
             },
             "llama3_1_70b":
             {
                 "mi300x":
                 {
                     "tokenizer_model": "NousResearch/Meta-Llama-3-70B",
                     "model_size": "70",
                     "batch_size": "256",
                     "micro_batch_size": "4",
                     "precision": "TE_FP16",
                     "sequence_length": "8192",
                     "tensor_parallelism": "8",
                     "pipeline_parallelism": "1",
                     "recompute": "0",
                     "fsdp": "0",
                     "result_dict":
                     {
                         "_example_throughput_per_gpu": "530.0",
                         "_example_tokens_per_gpu": "1100.0",
                         "throughput_per_gpu": "<changeme>",
                         "tokens_per_gpu": "<changeme>"
                     }
                 },
                 "mi325":
                 {
                     "tokenizer_model": "NousResearch/Meta-Llama-3-70B",
                     "model_size": "70",
                     "batch_size": "256",
                     "micro_batch_size": "4",
                     "precision": "TE_FP16",
                     "sequence_length": "8192",
                     "tensor_parallelism": "8",
                     "pipeline_parallelism": "1",
                     "recompute": "0",
                     "fsdp": "0",
                     "result_dict":
                     {
                         "_example_throughput_per_gpu": "550.0",
                         "_example_tokens_per_gpu": "1200.0",
                         "throughput_per_gpu": "<changeme>",
                         "tokens_per_gpu": "<changeme>"
                     }
                 }
             }
        }
    }

}
