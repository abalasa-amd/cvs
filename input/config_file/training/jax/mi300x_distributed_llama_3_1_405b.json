{

    "config":
    {
        "container_image": "rocm/jax-training:maxtext-v25.9",
        "container_name": "rocm-jax-llama3.1-405b",
        "distributed_training": "True",
        "enable_checkpointing": "False",
        "nnodes": "<changeme>",
        "coordinator_ip": "<changeme>",
        "training_steps": "30",
        "nic_type": "thor2",
        "_example_nccl_ib_hca_list": "bnxt_re0,bnxt_re1,bnxt_re2,bnxt_re3,bnxt_re4,bnxt_re5,bnxt_re7,bnxt_re8",
        "nccl_ib_hca_list": "<changeme>",
        "_example_nccl_ib_hca": "bnxt_re0,bnxt_re1,bnxt_re2,bnxt_re3,bnxt_re4,bnxt_re5,bnxt_re7,bnxt_re8",
        "nccl_ib_hca": "<changeme>",
        "nccl_socket_ifname": "<changeme>",
        "gloo_socket_ifname": "<changeme>",
        "_example_nccl_ib_gid_index": "3",
        "nccl_ib_gid_index": "<changeme>",
        "nccl_debug": "ERROR",
        "nccl_proto": "Simple",
        "gpu_max_hw_queues": "2",
        "nccl_ib_tc": "41",
        "nccl_ib_sl": "0",
        "nccl_checks_disable": "1",
        "nvte_ck_bwd_v3": "1",
        "nvte_ck_v3_bf16_cvt": "2",
        "xla_python_client_mem_fraction": "0.975",
	"xla_gpu_executable_warn_stuck_timeout": "90",
        "hf_token_file": "/home/{user-id}/.hf_token",
        "shm_size": "256G",
        "_comments_data_cache_dir": "This path should be accessible from all nodes like a common FS like NFS for distributed training",
        "data_cache_dir": "/home/{user-id}/cache",
        "mock_data": "True",
        "log_dir": "/home/{user-id}/LOGS",
        "dataset_source": 
        {
        },
        "container_config":
        {
            "device_list": [ "/dev/dri", "/dev/kfd", "/dev/infiniband/rdma_cm" ],
            "volume_dict":
            {
            "/home/{user-id}": "/home/{user-id}",
            "/dev/infiniband": "/dev/infiniband",
            "/usr/local/lib/libbnxt_re-rdmav34.so": "/usr/lib/x86_64-linux-gnu/libibverbs/libbnxt_re-rdmav34.so.host",
            "/lib/libibverbs.d": "/lib/libibverbs.d",
            "/tmp/TRAINING_LOGS": "/workspace/maxtext/output"
            },
            "env_dict":
            {
                "JAX_COORDINATOR_IP": "<changeme>",
                "JAX_COORDINATOR_PORT": "1234",
                "NNODES": "1",
                "JAX_DISTRIBUTED_INITIALIZATION_TIMEOUT_SECONDS": "1800",
		"JAX_DISTRIBUTED_HEARTBEAT_TIMEOUT_SECONDS": "900"
            }
        }
    },
    "model_params":
    {
        "multi_node":
        {
             "llama3.1-405b":
             {
                 "mi300x":
                 {
                     "tokenizer_model": "NousResearch/Meta-Llama-3-405B",
                     "model_size": "405",
		     "hardware": "gpu",
                     "attention": "cudnn_flash_te",
                     "dcn_data_parallelism": "1",
                     "dcn_fsdp_parallelism": "-1",
                     "dcn_pipeline_parallelism": "1",
                     "dcn_tensor_parallelism": "1",
                     "dcn_sequence_parallelism": "1",
                     "ici_fsdp_parallelism": "8",
                     "ici_data_parallelism": "1",
                     "ici_sequence_parallelism": "1",
                     "ici_tensor_parallelism": "1",
                     "ici_pipeline_parallelism": "1",
                     "remat_policy": "full",
                     "use_iota_embed": "true",
                     "scan_layers": "true",
                     "dataset_type": "synthetic",
                     "hf_path": "parquet",
                     "hf_train_files": "/home/{user-id}/cache/maxtext/data/c4/000*.parquet",
                     "tokenizer_path": "/home/{user-id}/cache/maxtext/Meta-Llama-405-B",
                     "async_checkpointing": "false",
                     "logits_dot_in_fp32": "false",
                     "megablox": "false",
                     "dtype": "bfloat16",
                     "batch_size": "128",
                     "quantization": "",
                     "quantize_kvcache": "false",
                     "kv_quant_axis": "heads_and_dkv",
                     "kv_quant_dtype": "int8",
                     "weight_dtype": "bfloat16",
                     "checkpoint_is_quantized": "false",
                     "per_device_batch_size": "2",
                     "max_target_length": "8192",
                     "skip_first_n_steps_for_profiler": "3",

                     "xla_flags":
                     {
                         "xla_gpu_enable_cublaslt": "True",
			 "xla_gpu_executable_warn_stuck_timeout": "90",
                         "xla_gpu_executable_terminate_timeout": "300",
                         "xla_gpu_first_collective_call_warn_stuck_timeout_seconds": "300",
                         "xla_gpu_first_collective_call_terminate_timeout_seconds": "1200",
                         "xla_gpu_graph_level": "0",
                         "xla_gpu_autotune_level": "4",
                         "xla_gpu_enable_reduce_scatter_combine_by_dim": "false",
                         "xla_gpu_reduce_scatter_combine_threshold_bytes": "8589934592",
                         "xla_gpu_all_reduce_combine_threshold_bytes": "8589934592",
                         "xla_gpu_all_gather_combine_threshold_bytes": "137438953472",
                         "xla_gpu_enable_all_gather_combine_by_dim": "FALSE"
                     },

                     "base_emb_dim": "16384",
                     "base_num_query_heads": "128",
                     "base_num_kv_heads": "8",
                     "base_num_decoder_layers": "126",
                     "base_mlp_dim": "53248",
                     "head_dim": "128",
                     "mlp_activations": ["silu","linear"],
                     "vocab_size": "128256",
                     "enable_dropout": "False",
                     "logits_via_embedding": "False",
                     "normalization_layer_epsilon": "1.0e-5",
                     "rope_max_timescale": "500_000",
                     "decoder_block": "llama2",

                     "micro_batch_size": "2",
                     "precision": "TE_FP8",
                     "sequence_length": "8192",
                     "tensor_parallelism": "1",
                     "pipeline_parallelism": "1",
                     "recompute": "0",
                     "fsdp": "0",
                     "result_dict":
                     {

			 "_example_tflops_per_sec_per_gpu": "380",
                         "_example_tokens_per_sec_per_gpu": "145",
			 "_comments": "Values change based on number of nodes",
			 "tflops_per_sec_per_gpu": "<changeme>",
                         "tokens_per_sec_per_gpu": "<changeme>"
                     }
                 }
             }

        }


    }

}
